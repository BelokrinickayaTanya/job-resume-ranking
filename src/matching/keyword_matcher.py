"""
–ú–æ–¥—É–ª—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö –Ω–∞–≤—ã–∫–æ–≤ (80% –≤–µ—Å–∞ –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Å–∫–æ—Ä–µ)
"""
from typing import Dict, List, Set, Tuple, Optional
import re
from difflib import SequenceMatcher
from collections import defaultdict


class KeywordMatcher:
    """
    –ú–∞—Ç—á–∏–Ω–≥ –Ω–∞–≤—ã–∫–æ–≤ —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏ –∏ fuzzy matching
    
    –í–µ—Å –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Å–∫–æ—Ä–µ: 80%
    """
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π
    SYNONYMS = {
        # –Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
        'python': ['python', 'python3', 'py', 'cpython', 'anaconda'],
        'javascript': ['javascript', 'js', 'ecmascript', 'nodejs', 'node', 'deno'],
        'typescript': ['typescript', 'ts', 'typed javascript'],
        'java': ['java', 'j2ee', 'jdk', 'jre', 'java ee', 'jakarta ee'],
        'c++': ['c++', 'cpp', 'cplusplus', 'c plus plus', 'stl', 'boost'],
        'c#': ['c#', 'csharp', 'c sharp', 'dotnet', '.net', 'net core', 'asp.net'],
        'php': ['php', 'php7', 'php8', 'laravel', 'symfony', 'composer'],
        'go': ['go', 'golang', 'go lang'],
        'rust': ['rust', 'rustlang'],
        'ruby': ['ruby', 'rb', 'ruby on rails', 'ror'],
        'swift': ['swift', 'ios development'],
        'kotlin': ['kotlin', 'android development'],
        'scala': ['scala', 'akka'],
        'perl': ['perl', 'cgi'],
        'r': ['r', 'r language', 'rstudio'],
        'matlab': ['matlab', 'simulink'],
        
        # –§—Ä–æ–Ω—Ç–µ–Ω–¥ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏
        'react': ['react', 'reactjs', 'react.js', 'react native', 'next.js', 'gatsby'],
        'angular': ['angular', 'angularjs', 'angular.js', 'angular 2+'],
        'vue': ['vue', 'vuejs', 'vue.js', 'nuxt', 'vite'],
        'svelte': ['svelte', 'sveltekit'],
        'jquery': ['jquery', '$', 'jquery ui'],
        'bootstrap': ['bootstrap', 'bootstrap4', 'bootstrap5', 'twitter bootstrap'],
        'tailwind': ['tailwind', 'tailwindcss', 'tailwind css'],
        'material ui': ['material ui', 'mui', 'material design'],
        
        # –ë—ç–∫–µ–Ω–¥ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏
        'django': ['django', 'django rest', 'drf'],
        'flask': ['flask', 'flask restful'],
        'fastapi': ['fastapi', 'fast api'],
        'spring': ['spring', 'spring boot', 'spring mvc', 'spring framework'],
        'express': ['express', 'expressjs', 'express.js', 'nodejs express'],
        'asp.net': ['asp.net', 'asp.net core', 'asp', '.net mvc'],
        
        # –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        'sql': ['sql', 'rdbms', 'relational database'],
        'mysql': ['mysql', 'mariadb', 'percona'],
        'postgresql': ['postgresql', 'postgres', 'pgsql'],
        'mongodb': ['mongodb', 'mongo', 'nosql', 'document database'],
        'redis': ['redis', 'key-value store', 'cache'],
        'cassandra': ['cassandra', 'cql', 'wide column'],
        'elasticsearch': ['elasticsearch', 'es', 'elk', 'elastic stack'],
        'oracle': ['oracle', 'oracle db', 'pl/sql'],
        'sqlite': ['sqlite', 'lite database'],
        'dynamodb': ['dynamodb', 'aws dynamodb'],
        'firebase': ['firebase', 'firestore', 'realtime database'],
        
        # Cloud –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
        'aws': ['aws', 'amazon web services', 'ec2', 's3', 'lambda', 'rds', 'cloudfront', 
                'route53', 'vpc', 'iam', 'dynamodb', 'ecs', 'eks', 'fargate'],
        'azure': ['azure', 'microsoft azure', 'azure devops', 'aad', 'blob storage', 
                  'azure functions', 'app service', 'sql azure'],
        'gcp': ['gcp', 'google cloud', 'google cloud platform', 'compute engine', 
                'cloud storage', 'bigquery', 'pub/sub', 'kubernetes engine'],
        'heroku': ['heroku', 'heroku platform'],
        'digitalocean': ['digitalocean', 'do', 'droplet'],
        
        # DevOps –∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è
        'docker': ['docker', 'container', 'docker compose', 'dockerfile'],
        'kubernetes': ['kubernetes', 'k8s', 'kube', 'openshift'],
        'jenkins': ['jenkins', 'jenkins ci', 'jenkins pipeline'],
        'gitlab ci': ['gitlab ci', 'gitlab pipeline', 'gitlab runner'],
        'github actions': ['github actions', 'gha', 'actions'],
        'terraform': ['terraform', 'iac', 'infrastructure as code'],
        'ansible': ['ansible', 'ansible playbook'],
        'chef': ['chef', 'chef cookbook'],
        'puppet': ['puppet', 'puppet manifest'],
        'prometheus': ['prometheus', 'prom', 'monitoring'],
        'grafana': ['grafana', 'dashboard', 'visualization'],
        
        # –°–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è –≤–µ—Ä—Å–∏–π
        'git': ['git', 'github', 'gitlab', 'bitbucket', 'version control', 'vcs'],
        'svn': ['svn', 'subversion', 'apache subversion'],
        'mercurial': ['mercurial', 'hg'],
        
        # –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã
        'linux': ['linux', 'unix', 'ubuntu', 'debian', 'centos', 'redhat', 'fedora', 
                  'arch', 'suse', 'opensuse', 'bash', 'shell', 'command line'],
        'windows': ['windows', 'win32', 'winapi', 'mfc', 'dotnet', 'powershell'],
        'macos': ['macos', 'os x', 'mac os x', 'darwin'],
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        'junit': ['junit', 'unit testing', 'test driven', 'tdd'],
        'pytest': ['pytest', 'python testing'],
        'selenium': ['selenium', 'webdriver', 'automation testing'],
        'cypress': ['cypress', 'e2e testing'],
        'jest': ['jest', 'javascript testing', 'react testing'],
        'mocha': ['mocha', 'chai', 'sinon'],
        
        # –û—á–µ—Ä–µ–¥–∏ –∏ —Å–æ–æ–±—â–µ–Ω–∏—è
        'rabbitmq': ['rabbitmq', 'message queue', 'amqp'],
        'kafka': ['kafka', 'apache kafka', 'pub sub'],
        'activemq': ['activemq', 'jms'],
        'sqs': ['sqs', 'amazon sqs', 'simple queue service'],
        
        # API –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
        'rest': ['rest', 'restful', 'rest api', 'restful api', 'rest webservice'],
        'graphql': ['graphql', 'gql', 'apollo', 'relay'],
        'grpc': ['grpc', 'protocol buffers', 'protobuf'],
        'soap': ['soap', 'soap webservice', 'wsdl'],
        
        # –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏
        'agile': ['agile', 'scrum', 'kanban', 'sprint', 'standup', 'retrospective'],
        'waterfall': ['waterfall', 'traditional development'],
        
        # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ ML
        'pandas': ['pandas', 'dataframe', 'data analysis'],
        'numpy': ['numpy', 'numerical python', 'array'],
        'scikit-learn': ['scikit-learn', 'sklearn', 'machine learning'],
        'tensorflow': ['tensorflow', 'tf', 'keras'],
        'pytorch': ['pytorch', 'torch'],
        'jupyter': ['jupyter', 'ipython', 'notebook'],
        'tableau': ['tableau', 'data visualization'],
        'power bi': ['power bi', 'powerbi', 'microsoft bi'],
        
        # –ú–æ–±–∏–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
        'android': ['android', 'android sdk', 'android studio', 'dalvik'],
        'ios': ['ios', 'iphone', 'ipad', 'apple', 'cocoa touch'],
        'react native': ['react native', 'rn', 'cross platform mobile'],
        'flutter': ['flutter', 'dart'],
        'xamarin': ['xamarin', 'xamarin forms', 'mono'],
        
        # ERP/CRM
        'salesforce': ['salesforce', 'sfdc', 'apex', 'soql'],
        'sap': ['sap', 'abap', 'sap hana'],
        'oracle erp': ['oracle erp', 'e-business suite', 'ebs'],
        
        # –°–∏—Å—Ç–µ–º—ã —Ç—Ä–µ–∫–∏–Ω–≥–∞
        'jira': ['jira', 'atlassian', 'issue tracking'],
        'confluence': ['confluence', 'wiki', 'documentation'],
        'trello': ['trello', 'kanban board'],
        'asana': ['asana', 'project management'],
        
        # –ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏
        'slack': ['slack', 'chatops'],
        'teams': ['teams', 'microsoft teams'],
        
        # –ò–≥—Ä—ã
        'unity': ['unity', 'unity3d', 'game engine'],
        'unreal': ['unreal', 'unreal engine', 'ue4', 'ue5'],
    }
    
    # –°–ø–∏—Å–æ–∫ —Å—Ç–æ–ø-—Å–ª–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    STOP_WORDS = {
        'a', 'an', 'the', 'and', 'or', 'but', 'if', 'because', 'as', 'until',
        'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',
        'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to',
        'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',
        'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why',
        'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other',
        'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',
        'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should',
        'now', 'experience', 'skill', 'knowledge', 'ability', 'proficient'
    }
    
    def __init__(self, fuzzy_threshold: float = 0.85):
        """
        Args:
            fuzzy_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è fuzzy matching (0.0-1.0)
        """
        self.fuzzy_threshold = fuzzy_threshold
        self.skill_cache = {}
        self.synonym_cache = {}
        
        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        self._build_synonym_index()
    
    def _extract_soft_skills(self, text: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ soft skills –∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–∏
        """
        soft_skills = {
            'remote', 'work from home', 'wfh', 'distributed team', 
            'async', 'asynchronous', 'communication', 'teamwork', 
            'collaboration', 'leadership', 'problem solving',
            'critical thinking', 'time management', 'agile', 'scrum',
            'self-motivated', 'independent', 'fast learner'
        }
        
        text_lower = text.lower()
        found = set()
        
        for skill in soft_skills:
            if skill in text_lower:
                found.add(skill)
        
        return list(found)

    def _build_synonym_index(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤"""
        self.synonym_to_canonical = {}
        for canonical, synonyms in self.SYNONYMS.items():
            for synonym in synonyms:
                self.synonym_to_canonical[synonym.lower()] = canonical
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–∞–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π —Ç–µ—Ä–º–∏–Ω
            self.synonym_to_canonical[canonical.lower()] = canonical
    
    def calculate_match_score(
        self, 
        resume_skills: List[str], 
        vacancy_skills: List[str],
        vacancy_text: Optional[str] = None,
        cv_experience: Optional[float] = None, 
        vacancy_required_years: Optional[int] = None
    ) -> Dict:
        """
        –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∞ –º–∞—Ç—á–∏–Ω–≥–∞ –Ω–∞–≤—ã–∫–æ–≤ —Å —É—á–µ—Ç–æ–º –≤–µ—Å–æ–≤ –∏ –≤–∞–∂–Ω–æ—Å—Ç–∏
        
        Args:
            resume_skills: –°–ø–∏—Å–æ–∫ –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ —Ä–µ–∑—é–º–µ
            vacancy_skills: –°–ø–∏—Å–æ–∫ —Ç—Ä–µ–±—É–µ–º—ã—Ö –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏
            vacancy_text: –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ (–¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤–µ—Å–æ–≤)
            
        Returns:
            {
                'score': 0-100,
                'matched': [...],
                'missing': [...],
                'partial': [...],
                'weights': {...},
                'match_details': {...}
            }
        """
        if not vacancy_skills:
            return {
                'score': 0,
                'matched': [],
                'missing': [],
                'partial': [],
                'weights': {},
                'match_details': {}
            }
        
        # 1. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–≤—ã–∫–∏
        resume_norm = self._normalize_skills(resume_skills)
        vacancy_norm = self._normalize_skills(vacancy_skills)
        soft_skills = self._extract_soft_skills(vacancy_text) if vacancy_text else []
        vacancy_norm.extend(soft_skills)
        
        # 2. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ—Å–∞ –Ω–∞–≤—ã–∫–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏)
        skill_weights = self._calculate_skill_weights(vacancy_text, vacancy_norm)
        
        # 3. –¢–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        exact_matches = self._find_exact_matches(resume_norm, vacancy_norm)
        
        # 4. –°–∏–Ω–æ–Ω–∏–º–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        synonym_matches = self._find_synonym_matches(resume_norm, vacancy_norm)
        
        # 5. Fuzzy —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        fuzzy_matches = self._find_fuzzy_matches(resume_norm, vacancy_norm)
        
        # 6. –ß–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (–≤—Ö–æ–∂–¥–µ–Ω–∏—è)
        partial_matches = self._find_partial_matches(resume_skills, vacancy_norm)
        
        # –í—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –≤–µ—Å–∞–º–∏
        all_matches = {}
        match_types = {}
        
        for skill in exact_matches:
            all_matches[skill] = skill_weights.get(skill, 1.0)
            match_types[skill] = 'exact'
            
        for skill in synonym_matches:
            if skill not in all_matches:
                all_matches[skill] = skill_weights.get(skill, 0.9)  # –°–∏–Ω–æ–Ω–∏–º = 90% –≤–µ—Å–∞
                match_types[skill] = 'synonym'
                
        for skill in fuzzy_matches:
            if skill not in all_matches:
                all_matches[skill] = skill_weights.get(skill, 0.8)  # Fuzzy = 80% –≤–µ—Å–∞
                match_types[skill] = 'fuzzy'
                
        for skill in partial_matches:
            if skill not in all_matches:
                all_matches[skill] = skill_weights.get(skill, 0.7)  # –ß–∞—Å—Ç–∏—á–Ω–æ–µ = 70% –≤–µ—Å–∞
                match_types[skill] = 'partial'
        
        # –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –Ω–∞–≤—ã–∫–∏
        missing = set(vacancy_norm) - set(all_matches.keys())
        
        # –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∞ —Å –≤–µ—Å–∞–º–∏
        total_weight = sum(skill_weights.get(skill, 1.0) for skill in vacancy_norm)
        matched_weight = sum(all_matches.get(skill, 0) for skill in all_matches)
        
        if total_weight > 0:
            score = (matched_weight / total_weight) * 100
        else:
            score = 0
        
        # –ë–æ–Ω—É—Å –∑–∞ –ø–æ–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö must-have –Ω–∞–≤—ã–∫–æ–≤
        must_have_bonus = self._calculate_must_have_bonus(vacancy_text, all_matches)
        score = min(100, score + must_have_bonus)
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞–≤—ã–∫–æ–≤
        critical_penalty = self._calculate_critical_penalty(vacancy_text, missing)
        score = max(0, score - critical_penalty)
        
        score = round(score, 1)
        # 1. –ë–£–°–¢ –î–õ–Ø REMOTE –í–ê–ö–ê–ù–°–ò–ô
        if vacancy_text and ('remote' in vacancy_text.lower() or 'work from home' in vacancy_text.lower()):
            score += 10  # +10% –±—É—Å—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –±—É—Å—Ç, –µ—Å–ª–∏ —É –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –µ—Å—Ç—å –ª–æ–∫–∞—Ü–∏—è (–Ω–µ –≤–∞–∂–Ω–æ –∫–∞–∫–∞—è)
            score += 5   # +5% –±—É—Å—Ç –∑–∞ –Ω–∞–ª–∏—á–∏–µ –ª–æ–∫–∞—Ü–∏–∏
            score = min(100, score)  # –ù–µ –ø—Ä–µ–≤—ã—à–∞–µ–º 100%

        # 2. –£–ß–ï–¢ –ü–ï–†–ï–ö–í–ê–õ–ò–§–ò–ö–ê–¶–ò–ò
        if cv_experience is not None and vacancy_required_years is not None:
            if cv_experience > vacancy_required_years * 2:
                score -= 5  # –®—Ç—Ä–∞—Ñ –∑–∞ overqualification
            elif cv_experience >= vacancy_required_years:
                score += 5  # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–ø—ã—Ç–∞
            score = max(0, min(100, score))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 0-100

        return {
            'score': score,
            'matched': list(all_matches.keys()),
            'missing': list(missing),
            'partial': list(partial_matches),
            'weights': skill_weights,
            'match_details': {
                'exact_matches': list(exact_matches),
                'synonym_matches': list(synonym_matches),
                'fuzzy_matches': list(fuzzy_matches),
                'match_types': match_types,
                'match_scores': all_matches
            }
        }
    
    def _normalize_skills(self, skills: List[str]) -> List[str]:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ –Ω–∞–≤—ã–∫–æ–≤"""
        normalized = []
        for skill in skills:
            if isinstance(skill, str):
                # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
                skill = skill.lower().strip()
                
                # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
                words = skill.split()
                filtered = [w for w in words if w not in self.STOP_WORDS]
                if filtered:
                    skill = ' '.join(filtered)
                
                normalized.append(skill)
        
        return list(set(normalized))
    
    def _find_exact_matches(self, resume_skills: List[str], vacancy_skills: List[str]) -> Set[str]:
        """–ü–æ–∏—Å–∫ —Ç–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π"""
        resume_set = set(resume_skills)
        vacancy_set = set(vacancy_skills)
        return resume_set & vacancy_set
    
    def _find_synonym_matches(self, resume_skills: List[str], vacancy_skills: List[str]) -> Set[str]:
        """–ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ —Å–∏–Ω–æ–Ω–∏–º–∞–º"""
        matches = set()
        
        # –°—Ç—Ä–æ–∏–º –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º
        resume_canonical = set()
        for skill in resume_skills:
            if skill in self.synonym_to_canonical:
                resume_canonical.add(self.synonym_to_canonical[skill])
            else:
                resume_canonical.add(skill)
        
        vacancy_canonical = set()
        for skill in vacancy_skills:
            if skill in self.synonym_to_canonical:
                vacancy_canonical.add(self.synonym_to_canonical[skill])
            else:
                vacancy_canonical.add(skill)
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
        for skill in vacancy_canonical & resume_canonical:
            matches.add(skill)
        
        return matches
    
    def _find_fuzzy_matches(self, resume_skills: List[str], vacancy_skills: List[str]) -> Set[str]:
        """–ü–æ–∏—Å–∫ –Ω–µ—á–µ—Ç–∫–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π"""
        matches = set()
        
        for v_skill in vacancy_skills:
            best_match = None
            best_ratio = 0
            
            for r_skill in resume_skills:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –¥–ª–∏–Ω–∞ —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è
                if abs(len(r_skill) - len(v_skill)) > 5:
                    continue
                    
                ratio = SequenceMatcher(None, r_skill, v_skill).ratio()
                if ratio > self.fuzzy_threshold and ratio > best_ratio:
                    best_ratio = ratio
                    best_match = v_skill
            
            if best_match:
                matches.add(best_match)
        
        return matches
    
    def _find_partial_matches(self, resume_skills: List[str], vacancy_skills: List[str]) -> Set[str]:
        """–ü–æ–∏—Å–∫ —á–∞—Å—Ç–∏—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (–æ–¥–Ω–æ —Å–ª–æ–≤–æ –∏–∑ —Ñ—Ä–∞–∑—ã)"""
        matches = set()
        
        for v_skill in vacancy_skills:
            v_words = set(v_skill.split())
            if len(v_words) <= 1:
                continue
                
            for r_skill in resume_skills:
                r_words = set(r_skill.split())
                # –ï—Å–ª–∏ –±–æ–ª—å—à–µ –ø–æ–ª–æ–≤–∏–Ω—ã —Å–ª–æ–≤ —Å–æ–≤–ø–∞–¥–∞–µ—Ç
                if len(v_words & r_words) >= len(v_words) / 2:
                    matches.add(v_skill)
                    break
        
        return matches
    
    def _calculate_skill_weights(self, vacancy_text: Optional[str], skills: List[str]) -> Dict[str, float]:
        """
        –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –Ω–∞–≤—ã–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –≤–∞–∂–Ω–æ—Å—Ç–∏ –≤ –≤–∞–∫–∞–Ω—Å–∏–∏
        
        –§–∞–∫—Ç–æ—Ä—ã:
        - –ß–∞—Å—Ç–æ—Ç–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
        - –ü–æ–∑–∏—Ü–∏—è –≤ —Ç–µ–∫—Å—Ç–µ (–ø–µ—Ä–≤—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
        - –ú–∞—Ä–∫–µ—Ä—ã –≤–∞–∂–Ω–æ—Å—Ç–∏ (must have, required, essential)
        """
        weights = {}
        
        if not vacancy_text:
            return {skill: 1.0 for skill in skills}
        
        vacancy_lower = vacancy_text.lower()
        
        for skill in skills:
            weight = 1.0
            
            # 1. –ß–∞—Å—Ç–æ—Ç–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
            count = vacancy_lower.count(skill)
            weight += min(count * 0.1, 0.3)  # –ú–∞–∫—Å +0.3
            
            # 2. –ü–æ–∏—Å–∫ –≤ –ø–µ—Ä–≤—ã—Ö 500 —Å–∏–º–≤–æ–ª–∞—Ö
            if skill in vacancy_lower[:500]:
                weight += 0.2
            
            # 3. –ú–∞—Ä–∫–µ—Ä—ã –≤–∞–∂–Ω–æ—Å—Ç–∏
            importance_markers = [
                (r'must have.*?' + re.escape(skill), 0.5),
                (r'required.*?' + re.escape(skill), 0.4),
                (r'essential.*?' + re.escape(skill), 0.4),
                (r'need.*?' + re.escape(skill), 0.3),
                (r'prefer.*?' + re.escape(skill), -0.2),
                (r'plus.*?' + re.escape(skill), -0.2),
                (r'nice to have.*?' + re.escape(skill), -0.3)
            ]
            
            for pattern, bonus in importance_markers:
                if re.search(pattern, vacancy_lower, re.IGNORECASE):
                    weight += bonus
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å (0.5 - 2.0)
            weight = max(0.5, min(2.0, weight))
            weights[skill] = round(weight, 2)
        
        return weights
    
    def _calculate_must_have_bonus(self, vacancy_text: Optional[str], matches: Dict) -> float:
        """–ë–æ–Ω—É—Å –∑–∞ –ø–æ–∫—Ä—ã—Ç–∏–µ must-have —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π"""
        if not vacancy_text:
            return 0
        
        bonus = 0
        vacancy_lower = vacancy_text.lower()
        
        # –ò—â–µ–º must-have —Å–µ–∫—Ü–∏—é
        must_have_pattern = r'(?:must have|required|essential|qualifications?)[:\s]+(.*?)(?:\n\s*\n|\.\s+[A-Z]|\Z)'
        must_have_section = re.search(must_have_pattern, vacancy_lower, re.DOTALL | re.IGNORECASE)
        
        if must_have_section:
            must_have_text = must_have_section.group(1)
            matched_skills = set(matches.keys())
            
            for skill in matched_skills:
                if skill in must_have_text:
                    bonus += 2  # +2% –∑–∞ –∫–∞–∂–¥—ã–π –ø–æ–∫—Ä—ã—Ç—ã–π must-have –Ω–∞–≤—ã–∫
        
        return min(bonus, 15)  # –ú–∞–∫—Å–∏–º—É–º 15% –±–æ–Ω—É—Å–∞
    
    def _calculate_critical_penalty(self, vacancy_text: Optional[str], missing: Set[str]) -> float:
        """–®—Ç—Ä–∞—Ñ –∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞–≤—ã–∫–æ–≤"""
        if not vacancy_text:
            return 0
        
        penalty = 0
        vacancy_lower = vacancy_text.lower()
        
        for skill in missing:
            # –ë–æ–ª—å—à–∏–π —à—Ç—Ä–∞—Ñ –µ—Å–ª–∏ skill —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –∫–∞–∫ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π
            critical_patterns = [
                r'must have.*?' + re.escape(skill),
                r'required.*?' + re.escape(skill),
                r'essential.*?' + re.escape(skill)
            ]
            
            for pattern in critical_patterns:
                if re.search(pattern, vacancy_lower, re.IGNORECASE):
                    penalty += 10  # -10% –∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ must-have
                    break
            else:
                penalty += 3  # -3% –∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ–±—ã—á–Ω–æ–≥–æ –Ω–∞–≤—ã–∫–∞
        
        return min(penalty, 40)  # –ú–∞–∫—Å–∏–º—É–º 40% —à—Ç—Ä–∞—Ñ–∞
    
    def extract_vacancy_requirements(self, vacancy_text: str) -> Dict:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–∏
        """
        requirements = {
            'must_have': [],
            'nice_to_have': [],
            'years_experience': None,
            'education': [],
            'certifications': []
        }
        
        text_lower = vacancy_text.lower()
        
        # 1. Must have / Required
        must_have_pattern = r'(?:must have|required|essential|minimum)[:\s]+(.*?)(?:\n\s*\n|\.\s+[A-Z]|\Z)'
        must_have_section = re.search(must_have_pattern, text_lower, re.DOTALL)
        if must_have_section:
            requirements['must_have'] = self._extract_skills_from_text(must_have_section.group(1))
        
        # 2. Nice to have / Preferred
        nice_pattern = r'(?:nice to have|preferred|plus|desired)[:\s]+(.*?)(?:\n\s*\n|\.\s+[A-Z]|\Z)'
        nice_section = re.search(nice_pattern, text_lower, re.DOTALL)
        if nice_section:
            requirements['nice_to_have'] = self._extract_skills_from_text(nice_section.group(1))
        
        # 3. –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã
        exp_pattern = r'(\d+)[\+]?\s*(?:plus\s*)?years?\s+of\s+experience'
        exp_match = re.search(exp_pattern, text_lower)
        if exp_match:
            requirements['years_experience'] = int(exp_match.group(1))
        
        # 4. –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        edu_patterns = [
            r'bachelor(?:["\']?s)?\s+(?:degree\s+)?in\s+([^\.]+)',
            r'master(?:["\']?s)?\s+(?:degree\s+)?in\s+([^\.]+)',
            r'phd\s+in\s+([^\.]+)',
            r'bs\s+in\s+([^\.]+)',
            r'ms\s+in\s+([^\.]+)'
        ]
        
        for pattern in edu_patterns:
            matches = re.findall(pattern, text_lower)
            requirements['education'].extend(matches)
        
        # 5. –°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
        cert_pattern = r'(?:certified|certification|certificate)[:\s]+([^\.]+)'
        cert_matches = re.findall(cert_pattern, text_lower)
        requirements['certifications'] = [c.strip() for c in cert_matches]
        
        return requirements
    
    def _extract_skills_from_text(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –±–ª–æ–∫–∞"""
        skills = []
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∑–∞–ø—è—Ç—ã–º, —Ç–æ—á–∫–∞–º —Å –∑–∞–ø—è—Ç–æ–π, –±—É–ª–ª–∏—Ç–∞–º
        parts = re.split(r'[,;‚Ä¢\n]', text)
        
        for part in parts:
            part = part.strip()
            if part and len(part) > 1:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —ç—Ç–æ—Ç –Ω–∞–≤—ã–∫ –≤ —Å–ª–æ–≤–∞—Ä–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
                for canonical, synonyms in self.SYNONYMS.items():
                    for synonym in synonyms:
                        if synonym in part.lower():
                            skills.append(canonical)
                            break
                    else:
                        continue
                    break
                else:
                    skills.append(part)
        
        return list(set(skills))
    
    def get_match_explanation(self, match_result: Dict) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–∞—Ç—á–∏–Ω–≥–∞
        """
        lines = []
        lines.append("üîç –ê–ù–ê–õ–ò–ó –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø –ù–ê–í–´–ö–û–í")
        lines.append("=" * 50)
        
        score = match_result['score']
        if score >= 80:
            lines.append(f"‚úÖ –û–ë–©–ò–ô –°–ö–û–†: {score}% - –û—Ç–ª–∏—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ!")
        elif score >= 60:
            lines.append(f"üëç –û–ë–©–ò–ô –°–ö–û–†: {score}% - –•–æ—Ä–æ—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ")
        elif score >= 40:
            lines.append(f"‚ö†Ô∏è –û–ë–©–ò–ô –°–ö–û–†: {score}% - –°—Ä–µ–¥–Ω–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ")
        else:
            lines.append(f"‚ùå –û–ë–©–ò–ô –°–ö–û–†: {score}% - –°–ª–∞–±–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ")
        
        lines.append("")
        lines.append("üìä –°–û–í–ü–ê–î–ï–ù–ò–Ø:")
        
        details = match_result.get('match_details', {})
        exact = details.get('exact_matches', [])
        synonym = details.get('synonym_matches', [])
        fuzzy = details.get('fuzzy_matches', [])
        
        if exact:
            lines.append(f"  ‚úì –¢–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è ({len(exact)}): {', '.join(exact[:5])}")
        if synonym:
            lines.append(f"  ‚Üª –°–∏–Ω–æ–Ω–∏–º—ã ({len(synonym)}): {', '.join(synonym[:3])}")
        if fuzzy:
            lines.append(f"  ~ –ë–ª–∏–∑–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è ({len(fuzzy)}): {', '.join(fuzzy[:3])}")
        
        missing = match_result.get('missing', [])
        if missing:
            lines.append("")
            lines.append("‚ùå –û–¢–°–£–¢–°–¢–í–£–Æ–¢:")
            for skill in missing[:8]:
                weight = match_result.get('weights', {}).get(skill, 1.0)
                if weight > 1.2:
                    lines.append(f"  ‚ö†Ô∏è {skill} (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –Ω–∞–≤—ã–∫!)")
                else:
                    lines.append(f"  ‚úó {skill}")
        
        return "\n".join(lines)