"""
–ú–æ–¥—É–ª—å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö –Ω–∞–≤—ã–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é KeyBERT
"""
from keybert import KeyBERT
from typing import List, Dict, Set
import re


class KeywordExtractor:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏ –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏
    TECH_SKILLS = {
        'python', 'java', 'javascript', 'typescript', 'c++', 'c#', 'php', 
        'go', 'rust', 'swift', 'kotlin', 'ruby', 'scala', 'perl',
        'react', 'angular', 'vue', 'nodejs', 'django', 'flask', 'spring',
        'sql', 'mysql', 'postgresql', 'mongodb', 'oracle', 'redis',
        'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins',
        'html', 'css', 'sass', 'less', 'webpack', 'babel',
        'tensorflow', 'pytorch', 'scikit-learn', 'pandas', 'numpy',
        'git', 'github', 'gitlab', 'jira', 'confluence',
        'linux', 'unix', 'windows', 'bash', 'powershell',
        'rest', 'graphql', 'soap', 'grpc'
    }
    
    def __init__(self):
        self.kw_model = KeyBERT(model='all-MiniLM-L6-v2')
        self.skill_cache = {}
    
    def extract_keywords(self, text: str, top_n: int = 20) -> List[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å –ø–æ–º–æ—â—å—é KeyBERT
        """
        if not text or len(text) < 50:
            return []
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤
        text_hash = hash(text[:500])
        if text_hash in self.skill_cache:
            return self.skill_cache[text_hash]
        
        try:
            keywords = self.kw_model.extract_keywords(
                text,
                keyphrase_ngram_range=(1, 2),
                stop_words='english',
                top_n=top_n,
                diversity=0.7
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑
            extracted = [kw[0].lower() for kw in keywords]

            # –í–ê–ñ–ù–û: –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑
            for kw in extracted:
                for word in kw.split():
                    if len(word) > 2 and word not in extracted:
                        extracted.append(word)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä—è–º–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –Ω–∞–≤—ã–∫–æ–≤
            tech_skills = self._extract_tech_skills(text)
            extracted.extend(tech_skills)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            extracted = list(set(extracted))
            
            self.skill_cache[text_hash] = extracted
            return extracted
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ KeyBERT: {e}")
            # Fallback –Ω–∞ regex –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
            return self._extract_tech_skills(text)
        

    def _extract_tech_skills(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –Ω–∞–≤—ã–∫–æ–≤ - –¢–û–õ–¨–ö–û —Ç–æ—á–Ω—ã–µ —Å–ª–æ–≤–∞!"""
        text_lower = text.lower()
        found_skills = set()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        #words = set(re.findall(r'\b[a-z0-9#+]+(?:[+\-.]?[a-z0-9]+)*\b', text_lower))
        
        for skill in self.TECH_SKILLS:
            # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤–∞
            if re.search(rf'\b{re.escape(skill)}\b', text_lower):
                found_skills.add(skill)
            elif skill in text_lower:
                pattern = rf'(^|\s|[,;])({re.escape(skill)})(\s|[,;]|$)'
                if re.search(pattern, text_lower):
                    found_skills.add(skill)    
            else:
                # –°–ø–µ—Ü–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è C++ –∏ C#
                if skill == 'c++' and 'c++' in text_lower:
                    found_skills.add('c++')
                elif skill == 'c#' and 'c#' in text_lower:
                    found_skills.add('c#')
        
        # –ò—Å–∫–ª—é—á–∞–µ–º –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è
        false_positives = {'go', 'r', 'c'}
        for fp in false_positives:
            if fp in found_skills:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ
                if not re.search(rf'\b{fp}\b', text_lower):
                    found_skills.remove(fp)
        
        return list(found_skills)
    
    def calculate_total_experience(self, resume_text: str, verbose: bool = False) -> float:
        """
        –ü–æ–¥—Å—á–µ—Ç –æ–ø—ã—Ç–∞
        """
        # –ò—â–µ–º –≤—Å–µ –≥–æ–¥–∞ –ø–æ–¥—Ä—è–¥
        pattern = r'(\d{4})\s*[-‚Äì‚Äî]\s*(\d{4}|now|present|current)'
        
        total_years = 0
        periods = []
        
        for match in re.finditer(pattern, resume_text, re.IGNORECASE):
            start = int(match.group(1))
            end_str = match.group(2).lower()
            
            if end_str in ['now', 'present', 'current']:
                end = 2026
            else:
                end = int(end_str)
            
            # –ò—Å–∫–ª—é—á–∞–µ–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
            context = resume_text[max(0, match.start()-50):min(len(resume_text), match.end()+50)].lower()
            if 'education' in context or 'university' in context:
                continue
                
            periods.append((start, end))
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–µ—Ä–∏–æ–¥—ã
        periods.sort()
        merged = []
        for start, end in periods:
            if not merged:
                merged.append([start, end])
            else:
                if start <= merged[-1][1]:
                    merged[-1][1] = max(merged[-1][1], end)
                else:
                    merged.append([start, end])
        
        # –°—É–º–º–∏—Ä—É–µ–º
        for start, end in merged:
            total_years += (end - start)
        
        if verbose:
            print(f"\n   üìÖ –ü–µ—Ä–∏–æ–¥—ã: {periods}")
            print(f"   üìÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ: {merged}")
            print(f"   ‚úÖ –û–ø—ã—Ç: {total_years} –ª–µ—Ç")
        
        return float(total_years)

    def _extract_tech_section(self, text: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ–∫—Ü–∏–∏ Technologies & Frameworks"""
        patterns = [
            r'(?:technologies\s*(?:&\s*)?frameworks?|tech\s*stack|tools\s*summary)[:\s]*(.+?)(?=\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:skills|competencies)[:\s]*(.+?)(?=\n\s*\n|\n\s*[A-Z]|\Z)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                return match.group(1)
        return ""
    
    def _extract_by_category(self, text: str, category: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º """
        text_lower = text.lower()
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ –Ω–∞–≤—ã–∫–æ–≤
        category_map = {
            'programming': {
                'java', 'javascript', 'python', 'c++', 'c#', 'php', 'ruby', 
                'swift', 'kotlin', 'r-style', 'typescript', 'go', 'rust', 'scala'
            },
            'framework': {
                'spring', 'spring boot', 'springboot', 'spring mvc', 'spring security',
                'hibernate', 'jpa', 'jdbc', 'junit', 'bootstrap', 'bootstrap3', 
                'jquery', 'react', 'angular', 'vue', 'nodejs'
            },
            'database': {
                'mysql', 'mongodb', 'postgresql', 'oracle', 'redis', 'sql', 
                'nosql', 'mariadb', 'cassandra', 'elasticsearch'
            },
            'tool': {
                'git', 'github', 'maven', 'eclipse', 'intellij', 'postman', 
                'swagger', 'jira', 'confluence', 'jenkins', 'docker'
            }
        }
        
        found = set()
        
        for skill in category_map.get(category, set()):
            # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤–∞
            if re.search(rf'\b{re.escape(skill)}\b', text_lower):
                found.add(skill)
            # –°–ø–µ—Ü–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
            elif ' ' in skill and skill in text_lower:
                found.add(skill)
            # –°–ø–µ—Ü–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è springboot
            elif skill == 'springboot' and 'spring boot' in text_lower:
                found.add('springboot')
        
        return list(found)
    
    def extract_skills_from_resume(self, resume_text: str) -> Dict[str, List[str]]:
        """
        –£–¥–æ–±–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤—Å–µ—Ö –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ —Ä–µ–∑—é–º–µ
        """
        all_skills = self.extract_keywords(resume_text, top_n=40)
        
        return {
            'all_skills': all_skills,
            'programming_languages': self._extract_by_category(resume_text, 'programming'),
            'frameworks': self._extract_by_category(resume_text, 'framework'),
            'databases': self._extract_by_category(resume_text, 'database'),
            'tools': self._extract_by_category(resume_text, 'tool'),
            'cloud': self._extract_by_category(resume_text, 'cloud')
        }