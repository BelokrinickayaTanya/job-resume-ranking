
"""
Job Vacancy Ranking System
–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
"""
import re
import os
import sys
import argparse
from pathlib import Path
import pickle
import json
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime

import pandas as pd
import numpy as np
from tqdm import tqdm

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π –ø—Ä–æ–µ–∫—Ç–∞
from src.pipeline.document_loader import DocumentLoader
from src.pipeline.text_extractor import TextExtractor
from src.pipeline.data_saver import DataSaver, DataLoader

from src.analysis.language_detector import LanguageDetector
from src.analysis.keyword_extractor import KeywordExtractor
from src.analysis.named_entity import NamedEntityExtractor
from src.analysis.experience_calculator import ExperienceCalculator
from src.analysis.grammar_checker import GrammarChecker
from src.analysis.error_detector import ErrorDetector

from src.matching.keyword_matcher import KeywordMatcher
from src.matching.tfidf_matcher import TfidfMatcher, AdaptiveTfidfMatcher
from src.matching.semantic_matcher import SemanticMatcher
from src.matching.unified_scorer import UnifiedScorer, MatchResult

from src.ranking.ranker import VacancyRanker, EnsembleRanker, RankingResult
from src.ranking.vm_method import VMMethod, VMOptimizer

from src.evaluation.metrics import RankingMetrics, Evaluator

# ============================================
# –ò–ú–ü–û–†–¢ GROUND TRUTH - –í–°–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï –°–£–©–ï–°–¢–í–£–Æ–¢!
# ============================================
try:
    from data.annotations.ground_truth import (
        ANNOTATOR_1_RANKINGS,        # ‚úÖ —Å–ø–∏—Å–æ–∫ —Ä–∞–Ω–≥–æ–≤ –∞–Ω–Ω–æ—Ç–∞—Ç–æ—Ä–∞ 1
        ANNOTATOR_2_RANKINGS,        # ‚úÖ —Å–ø–∏—Å–æ–∫ —Ä–∞–Ω–≥–æ–≤ –∞–Ω–Ω–æ—Ç–∞—Ç–æ—Ä–∞ 2
        GROUND_TRUTH_AVERAGE,        # ‚úÖ —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ —Ä–∞–Ω–≥–∏ (–í–´–ß–ò–°–õ–ï–ù!)
        GROUND_TRUTH_DICT,           # ‚úÖ —Å–ª–æ–≤–∞—Ä—å {cv_id: [rank1,...,rank5]}
        validate_rankings,           # ‚úÖ —Ñ—É–Ω–∫—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        get_annotator_agreement     # ‚úÖ —Ñ—É–Ω–∫—Ü–∏—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
    )
    
    GROUND_TRUTH_AVAILABLE = True
    print("‚úÖ Ground truth annotations loaded successfully")
    print(f"   CVs with ground truth: {len(GROUND_TRUTH_DICT)}")
    print(f"   Ground truth average computed: {len(GROUND_TRUTH_AVERAGE)} consensus rankings")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ç–æ—Ä–æ–≤
    agreement = get_annotator_agreement()
    print(f"   Annotator agreement: {agreement['mean_spearman']:.3f} (Spearman)")
    
    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
    valid1 = validate_rankings(ANNOTATOR_1_RANKINGS)
    valid2 = validate_rankings(ANNOTATOR_2_RANKINGS)
    print(f"   Annotator 1 rankings valid: {valid1}")
    print(f"   Annotator 2 rankings valid: {valid2}")
    
except ImportError as e:
    print(f"‚ö†Ô∏è Ground truth not available: {e}")
    print("   Please ensure data/annotations/ground_truth.py exists")
    GROUND_TRUTH_AVAILABLE = False
    
    # –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
    ANNOTATOR_1_RANKINGS = []
    ANNOTATOR_2_RANKINGS = []
    GROUND_TRUTH_AVERAGE = []
    GROUND_TRUTH_DICT = {}
    
    # –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π
    def validate_rankings(x): return False
    def compute_consensus_rankings(x, y): return []
    def get_ground_truth(cv_id): return [1, 2, 3, 4, 5]
    def get_all_ground_truth(): return {}
    def get_annotator_agreement(): 
        return {'mean_spearman': 0.0, 'min_spearman': 0.0, 'max_spearman': 0.0, 'std_spearman': 0.0}

class JobRankingSystem:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å —Å–∏—Å—Ç–µ–º—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—é–º–µ-–≤–∞–∫–∞–Ω—Å–∏–π
    """
    
    def __init__(self, 
                 cv_dir: str = "data/CV", 
                 vacancies_file: str = "data/vacancies/5_vacancies.csv",
                 output_dir: str = "results"):
        """
        Args:
            cv_dir: –ü–∞–ø–∫–∞ —Å —Ä–µ–∑—é–º–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DOCX
            vacancies_file: CSV —Ñ–∞–π–ª —Å 5 –≤–∞–∫–∞–Ω—Å–∏—è–º–∏
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        self.cv_dir = cv_dir
        self.vacancies_file = vacancies_file
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.loader = DocumentLoader(cv_dir, vacancies_file)
        self.text_extractor = TextExtractor()
        self.data_saver = DataSaver()
        
        # –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–¥—É–ª–∏
        self.keyword_extractor = KeywordExtractor()
        self.ner_extractor = NamedEntityExtractor()
        self.experience_calculator = ExperienceCalculator()
        self.grammar_checker = GrammarChecker(use_languagetool=False)
        self.error_detector = ErrorDetector()
        
        # –ú–∞—Ç—á–∏–Ω–≥ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
        self.unified_scorer = UnifiedScorer(
            use_adaptive_tfidf=True,
            semantic_model='mini',
            device='cpu'
        )
        self.ranker = VacancyRanker()
        self.ensemble_ranker = EnsembleRanker()
        
        # VM –º–µ—Ç–æ–¥ –∏–∑ —Å—Ç–∞—Ç—å–∏
        self.vm_method = VMMethod(
            resume_text_type='full',
            vacancy_text_type='summary',
            representation='char_ngrams',
            ngram_range=(1, 3),
            summary_sentences=10
        )
        
        # –î–∞–Ω–Ω—ã–µ
        self.cv_data = {}      # {cv_id: {'text': str, 'skills': List, 'experience': float, ...}}
        self.vacancies = {}    # {vac_id: {'title': str, 'description': str, 'skills': List, ...}}
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.ranking_results = {}
        self.evaluation_results = []
        
    def load_data(self, limit_cvs: Optional[int] = None, english_only: bool = True, verbose: bool = False) -> Tuple[Dict, Dict]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            limit_cvs: –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥—Ä—É–∂–∞–µ–º—ã—Ö —Ä–µ–∑—é–º–µ
            english_only: –¢–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Ä–µ–∑—é–º–µ
        """
        print("\n" + "=" * 70)
        print("üìÇ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•".center(70))
        print("=" * 70)
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—é–º–µ
        print("\nüîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—é–º–µ –∏–∑ DOCX —Ñ–∞–π–ª–æ–≤...")
        cv_texts = self.loader.load_all_cvs()
        
        if limit_cvs:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ N —Ä–µ–∑—é–º–µ
            cv_ids = sorted(cv_texts.keys(), key=lambda x: int(x))
            cv_texts = {k: cv_texts[k] for k in cv_ids[:limit_cvs]}
            print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω—ã —Ä–µ–∑—é–º–µ: {list(cv_texts.keys())}")
        
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ä–µ–∑—é–º–µ: {len(cv_texts)}")
        
        # 2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —è–∑—ã–∫—É
        if english_only:
            print("\nüîÑ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Ä–µ–∑—é–º–µ...")
            english_cvs = {}
            for cv_id, text in tqdm(cv_texts.items(), desc="   Detecting language"):
                if LanguageDetector.is_english(text):
                    english_cvs[cv_id] = text
                else:
                    print(f"   ‚ö†Ô∏è –†–µ–∑—é–º–µ {cv_id} –ø—Ä–æ–ø—É—â–µ–Ω–æ (–Ω–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)")
            cv_texts = english_cvs
            print(f"   –ê–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Ä–µ–∑—é–º–µ: {len(cv_texts)}")
        
        # 3. –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ä–µ–∑—é–º–µ
        print("\nüî¨ –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ...")
        for cv_id, text in tqdm(cv_texts.items(), desc="   Processing"):
            # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
            cleaned_text = self.text_extractor.clean_text(text)
            
            # –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥—ã KeywordExtractor
            all_skills = self.keyword_extractor.extract_keywords(cleaned_text, top_n=40)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–≤—ã–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            programming = self.keyword_extractor._extract_by_category(cleaned_text, 'programming')
            frameworks = self.keyword_extractor._extract_by_category(cleaned_text, 'framework')
            databases = self.keyword_extractor._extract_by_category(cleaned_text, 'database')
            tools = self.keyword_extractor._extract_by_category(cleaned_text, 'tool')
            
            skills_data = {
                'all_skills': all_skills,
                'programming_languages': programming,
                'frameworks': frameworks,
                'databases': databases,
                'tools': tools
            }
            
            if verbose:
                print(f"\n   üìç –†–µ–∑—é–º–µ {cv_id}:")
                print(f"      –ù–∞–≤—ã–∫–∏ ({len(all_skills)}): {', '.join(all_skills[:15])}")
                print(f"      –Ø–∑—ã–∫–∏: {programming}")
                print(f"      –§—Ä–µ–π–º–≤–æ—Ä–∫–∏: {frameworks}")
                print(f"      –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {databases}")
                print(f"      –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: {tools}")

            # === NER: –¢–û–õ–¨–ö–û –î–õ–Ø –ü–û–î–°–ß–ï–¢–ê –û–ü–´–¢–ê ===
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–∏–æ–¥—ã —Ä–∞–±–æ—Ç—ã —á–µ—Ä–µ–∑ NER (–∫–∞–∫ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫ regex)
            ner_periods = self.ner_extractor.extract_work_periods_ner(cleaned_text)
            
            # –ü–æ–ª—É—á–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å–≤–æ–¥–∫—É (—Ç–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞—Ç)
            entity_summary = self.ner_extractor.get_entity_summary(cleaned_text)
            
            # === –ü–û–î–°–ß–ï–¢ –û–ü–´–¢–ê (REGEX + NER) ===
            # –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ–¥—Å—á–µ—Ç —á–µ—Ä–µ–∑ regex
            experience_regex = self.experience_calculator.calculate_total_experience(
                cleaned_text, 
                verbose=verbose
            )
            
            # –ï—Å–ª–∏ regex –Ω–µ –Ω–∞—à–µ–ª –ø–µ—Ä–∏–æ–¥—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º NER
            if experience_regex == 0.0 and ner_periods:
                total_years = 0
                for start, end in ner_periods:
                    total_years += (end - start)
                experience = float(total_years)
                experience_method = 'ner'
                if verbose:
                    print(f"   ü§ñ NER: –Ω–∞–π–¥–µ–Ω—ã –ø–µ—Ä–∏–æ–¥—ã {ner_periods}, –æ–ø—ã—Ç: {experience} –ª–µ—Ç")
            else:
                experience = experience_regex
                experience_method = 'regex'
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏
            grammar_result = self.grammar_checker.check(cleaned_text[:5000])
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –æ—à–∏–±–æ–∫
            errors = self.error_detector.detect_all(cleaned_text)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            self.cv_data[cv_id] = {
                'id': cv_id,
                'text': cleaned_text,
                'raw_text': text,
                'skills': skills_data['all_skills'],
                'skills_by_category': skills_data,
                'experience': experience,
                'experience_method': experience_method,  # –æ—Ç–∫—É–¥–∞ –≤–∑—è–ª–∏ –æ–ø—ã—Ç
                'ner_periods': ner_periods,              # –ø–µ—Ä–∏–æ–¥—ã –æ—Ç NER
                'ner_dates_count': entity_summary['dates_found'],  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞—Ç
                'entities': entity_summary,
                'grammar_score': grammar_result['score'],
                'grammar_issues': grammar_result.get('total_issues', 0),
                'error_count': errors['total_issues'],
                'word_count': len(cleaned_text.split()),
                'has_email': 'email' in str(errors.get('stats', {})),
                'has_phone': 'phone' in str(errors.get('stats', {}))
            }
        
        print(f"\n‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ä–µ–∑—é–º–µ: {len(self.cv_data)}")
        
        # 4. –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π
        print("\nüîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π...")
        df_vacancies = self.loader.load_vacancies()
        
        for _, row in df_vacancies.iterrows():
            vac_id = row['vacancy_id']
            description = row['job_description']
            
            # –û—á–∏—Å—Ç–∫–∞
            cleaned_desc = self.text_extractor.clean_text(description)
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏
            vac_skills = self.keyword_extractor.extract_keywords(cleaned_desc, top_n=30)
            
            required_years = None
            exp_match = re.search(r'(\d+)[\+]?\s*(?:plus\s*)?years?\s+of\s+experience', description, re.IGNORECASE)
            if exp_match:
                required_years = int(exp_match.group(1))
            
            
            self.vacancies[vac_id] = {
                'id': vac_id,
                'title': row['job_title'],
                'description': cleaned_desc,
                'raw_description': description,
                'skills': vac_skills,
                'required_years': required_years, 
                'uid': row['uid']
            }
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(self.vacancies)}")
        
        # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self._save_processed_data()
        
        return self.cv_data, self.vacancies
    
    def _save_processed_data(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—é–º–µ
        for cv_id, cv_data in self.cv_data.items():
            self.data_saver.save_processed_resume(cv_id, cv_data)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏
        for vac_id, vac_data in self.vacancies.items():
            self.data_saver.save_processed_vacancy(vac_id, vac_data)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞—Ç—É
        metadata = {
            'num_cvs': len(self.cv_data),
            'num_vacancies': len(self.vacancies),
            'cv_ids': list(self.cv_data.keys()),
            'vacancy_ids': list(self.vacancies.keys()),
            'timestamp': datetime.now().isoformat()
        }
        
        self.data_saver.save_json(metadata, 'metadata', subdir='')
    
    def analyze_experience_distribution(self) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–ø—ã—Ç–∞"""
        experiences = [data['experience'] for data in self.cv_data.values()]
        
        if not experiences:
            return {}
        
        stats = {
            'mean': float(np.mean(experiences)),
            'median': float(np.median(experiences)),
            'min': float(np.min(experiences)),
            'max': float(np.max(experiences)),
            'std': float(np.std(experiences)),
            'count': len(experiences)
        }
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º
        levels = {
            'Junior (<3)': sum(1 for e in experiences if e < 3),
            'Middle (3-5)': sum(1 for e in experiences if 3 <= e < 5),
            'Senior (5-8)': sum(1 for e in experiences if 5 <= e < 8),
            'Lead (8+)': sum(1 for e in experiences if e >= 8)
        }
        
        stats['levels'] = levels
        stats['level_percentages'] = {
            k: round(v / len(experiences) * 100, 1) 
            for k, v in levels.items()
        }
        
        print("\n" + "=" * 70)
        print("üìä –ê–ù–ê–õ–ò–ó –û–ü–´–¢–ê –ö–ê–ù–î–ò–î–ê–¢–û–í".center(70))
        print("=" * 70)
        print(f"   –°—Ä–µ–¥–Ω–∏–π –æ–ø—ã—Ç: {stats['mean']:.1f} –ª–µ—Ç")
        print(f"   –ú–µ–¥–∏–∞–Ω–Ω—ã–π –æ–ø—ã—Ç: {stats['median']:.1f} –ª–µ—Ç")
        print(f"   –ú–∏–Ω/–ú–∞–∫—Å: {stats['min']:.1f} - {stats['max']:.1f} –ª–µ—Ç")
        print(f"\n   üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º:")
        for level, count in levels.items():
            print(f"      {level}: {count} ({stats['level_percentages'][level]}%)")
        
        return stats
    
    def run_ranking(self, 
                    method: str = 'unified', 
                    save_results: bool = True,
                    verbose: bool = True) -> Dict[int, List[int]]:
        """
        –ó–∞–ø—É—Å–∫ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã–±—Ä–∞–Ω–Ω—ã–º –º–µ—Ç–æ–¥–æ–º
        
        Args:
            method: 'unified', 'vm_method', 'okapi_bm25', 'bert_rank', 'ensemble'
            save_results: –°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
            verbose: –î–µ—Ç–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
        """
        print("\n" + "=" * 70)
        print(f"üéØ –†–ê–ù–ñ–ò–†–û–í–ê–ù–ò–ï –ú–ï–¢–û–î–û–ú: {method.upper()}".center(70))
        print("=" * 70)
        
        if not self.cv_data or not self.vacancies:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ load_data()")
            return {}
        
        predictions = {}
        
        # –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞
        for cv_id, cv_data in tqdm(self.cv_data.items(), 
                                  desc=f"   –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ {method}",
                                  disable=not verbose):
            
            if method == 'unified':
                result = self.ranker.rank_unified(
                    cv_id=cv_id,
                    cv_text=cv_data['text'],
                    cv_skills=cv_data['skills'],
                    cv_experience=cv_data['experience'], 
                    vacancies=self.vacancies
                )

            elif method == 'bidirectional':
                result = self.ensemble_ranker.rank_bidirectional(
                    cv_id=cv_id,
                    cv_data=cv_data,
                    vacancies=self.vacancies,
                    all_cvs=self.cv_data,  # –ü–µ—Ä–µ–¥–∞–µ–º –í–°–ï —Ä–µ–∑—é–º–µ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
                    cv_experience=cv_data['experience']
                )
            elif method == 'competition':
                result = self.ensemble_ranker.rank_with_competition(
                    cv_id=cv_id,
                    cv_data=cv_data,
                    vacancies=self.vacancies,
                    all_cvs=self.cv_data,
                    cv_experience=cv_data['experience']
                )    
            elif method == 'vm_method':
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º VM –º–µ—Ç–æ–¥ –∏–∑ —Å—Ç–∞—Ç—å–∏
                rankings = self.vm_method.get_rankings(
                    resume_text=cv_data['text'],
                    vacancies=self.vacancies,
                    resume_keywords=cv_data['skills']
                )
                from src.ranking.ranker import RankingResult
                result = RankingResult(
                    cv_id=cv_id,
                    rankings=rankings,
                    scores=[0]*5,
                    method='vm_method'
                )
            elif method == 'okapi_bm25':
                result = self.ranker.rank_okapi_bm25(
                    cv_id=cv_id,
                    cv_text=cv_data['text'],
                    vacancies=self.vacancies
                )
            elif method == 'bert_rank':
                result = self.ranker.rank_bert(
                    cv_id=cv_id,
                    cv_text=cv_data['text'],
                    vacancies=self.vacancies
                )
            elif method == 'ensemble':
                result = self.ensemble_ranker.rank_ensemble(
                    cv_id=cv_id,
                    cv_text=cv_data['text'],
                    cv_skills=cv_data['skills'],
                    vacancies=self.vacancies,
                    cv_experience=cv_data['experience']
                )
            else:
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥: {method}")
            
            predictions[cv_id] = result.rankings
        
        if verbose:
            print(f"\n   üìä –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è CV {cv_id}:")
            print(f"      –í–∞–∫–∞–Ω—Å–∏—è 1: {result.rankings[0]} —Ä–∞–Ω–≥")
            print(f"      –í–∞–∫–∞–Ω—Å–∏—è 2: {result.rankings[1]} —Ä–∞–Ω–≥")
            print(f"      –í–∞–∫–∞–Ω—Å–∏—è 3: {result.rankings[2]} —Ä–∞–Ω–≥")
            print(f"      –í–∞–∫–∞–Ω—Å–∏—è 4: {result.rankings[3]} —Ä–∞–Ω–≥")
            print(f"      –í–∞–∫–∞–Ω—Å–∏—è 5: {result.rankings[4]} —Ä–∞–Ω–≥")
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å ground truth, –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            if cv_id in GROUND_TRUTH_DICT:
                gt = GROUND_TRUTH_DICT[cv_id]
                print(f"      üìå Ground truth: {gt}")
                
                # –ü–æ–¥—Å—á–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ top-1
                top1_pred = result.rankings.index(1) + 1  # –ö–∞–∫–∞—è –≤–∞–∫–∞–Ω—Å–∏—è –Ω–∞ 1 –º–µ—Å—Ç–µ
                top1_gt = gt.index(1) + 1
                if top1_pred == top1_gt:
                    print(f"      ‚úÖ Top-1 —Å–æ–≤–ø–∞–¥–∞–µ—Ç: –í–∞–∫–∞–Ω—Å–∏—è {top1_pred}")
                else:
                    print(f"      ‚ùå Top-1 –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ {top1_pred}, –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å {top1_gt}")
                self.ranking_results[method] = predictions
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                if save_results:
                    self._save_ranking_results(method, predictions)
                
                # –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                if verbose and predictions:
                    cv_with_gt = [cv for cv in predictions if cv in GROUND_TRUTH_DICT]
                    print(f"\n   ‚úÖ –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–æ —Ä–µ–∑—é–º–µ: {len(predictions)}")
                    print(f"   üìä –° ground truth: {len(cv_with_gt)}")
        
        return predictions
    
    def _save_ranking_results(self, method: str, predictions: Dict[int, List[int]]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è"""
        # CSV —Ñ–æ—Ä–º–∞—Ç
        results_list = []
        for cv_id, rankings in predictions.items():
            results_list.append({
                'cv_id': cv_id,
                'rankings': str(rankings),
                'rank_vac1': rankings[0],
                'rank_vac2': rankings[1],
                'rank_vac3': rankings[2],
                'rank_vac4': rankings[3],
                'rank_vac5': rankings[4]
            })
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = self.output_dir / f"rankings_{method}_{timestamp}.csv"
        
        df = pd.DataFrame(results_list)
        df.to_csv(filename, index=False, encoding='utf-8')
        print(f"\n   üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filename}")
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ pickle –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        pickle_file = self.output_dir / f"rankings_{method}_{timestamp}.pkl"
        with open(pickle_file, 'wb') as f:
            pickle.dump(predictions, f)
    
    def evaluate_all_methods(self, methods: Optional[List[str]] = None) -> pd.DataFrame:
        """
        –û—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        if not GROUND_TRUTH_AVAILABLE:
            print("\n‚ùå Ground truth –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω. –û—Ü–µ–Ω–∫–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞.")
            return pd.DataFrame()
        
        print("\n" + "=" * 70)
        print("üìè –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê –†–ê–ù–ñ–ò–†–û–í–ê–ù–ò–Ø".center(70))
        print("=" * 70)
        
        if methods is None:
            # ‚úÖ –î–û–ë–ê–í–õ–Ø–ï–ú BIDIRECTIONAL –í –°–ü–ò–°–û–ö!
            methods = ['unified', 'vm_method', 'okapi_bm25', 'bert_rank', 'ensemble', 'bidirectional']
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–µ—Ç–æ–¥—ã, –µ—Å–ª–∏ –µ—â–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã
        for method in methods:
            if method not in self.ranking_results:
                print(f"\nüîÑ –ú–µ—Ç–æ–¥ {method} –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω. –ó–∞–ø—É—Å–∫–∞–µ–º...")
                self.run_ranking(method, save_results=True, verbose=False)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è evaluator
        evaluator = Evaluator(GROUND_TRUTH_DICT)
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞

        for method in methods:
            if method in self.ranking_results:
                predictions = self.ranking_results[method]
                
                eval_predictions = {
                    cv_id: pred for cv_id, pred in predictions.items()
                    if cv_id in GROUND_TRUTH_DICT
                }
                
                if eval_predictions:
                    # ‚úÖ –î–ª—è bidirectional –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É
                    if method == 'bidirectional':
                        results = evaluator.evaluate_bidirectional(eval_predictions, method.upper())
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–µ—Ç—Ä–∏–∫—É
                        print(f"\nüìä {method.upper()}:")
                        print(f"   Krippendorff's Alpha: {results['combined_krippendorff_alpha']:.4f}")
                        print(f"   Spearman's Rho: {results['combined_spearman_rho']:.4f}")
                        print(f"   Accuracy@1: {results['combined_accuracy_at_1']:.4f}")
                    else:
                        results = evaluator.evaluate(eval_predictions, method.upper())
                        print(f"\nüìä {method.upper()}:")
                        print(f"   Krippendorff's Alpha: {results['krippendorff_alpha']:.4f}")
                        print(f"   Spearman's Rho: {results['spearman_rho']:.4f}")
                        print(f"   Accuracy@1: {results['accuracy_at_1']:.4f}")
                        print(f"   NDCG@5: {results['ndcg@5']:.4f}")
                    
                    self.evaluation_results.append(results)
                    
                    print(f"\nüìä {method.upper()}:")
                    print(f"   Krippendorff's Alpha: {results.get('krippendorff_alpha', results.get('combined_krippendorff_alpha', 0)):.4f}")
                    print(f"   Spearman's Rho: {results.get('spearman_rho', results.get('combined_spearman_rho', 0)):.4f}")
                    print(f"   Accuracy@1: {results.get('accuracy_at_1', results.get('combined_accuracy_at_1', 0)):.4f}")
                    print(f"   NDCG@5: {results.get('ndcg@5', 0):.4f}")
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        print("\n" + "=" * 70)
        print("üèÜ –ò–¢–û–ì–û–í–û–ï –°–†–ê–í–ù–ï–ù–ò–ï".center(70))
        print("=" * 70)
        
        evaluator.print_comparison()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        df_comparison = evaluator.compare_methods()
        comparison_file = self.output_dir / "method_comparison.csv"
        df_comparison.to_csv(comparison_file, index=False)
        print(f"\nüíæ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {comparison_file}")
        
        return df_comparison
    
    def generate_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        print("\n" + "=" * 70)
        print("üìù –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–ß–ï–¢–ê".center(70))
        print("=" * 70)
        
        report_lines = []
        report_lines.append("# Job Vacancy Ranking System Report")
        report_lines.append("")
        report_lines.append(f"**–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")
        
        # 1. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
        report_lines.append("## üìä Dataset Statistics")
        report_lines.append("")
        report_lines.append(f"- **–†–µ–∑—é–º–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ:** {len(self.cv_data)}")
        report_lines.append(f"- **–í–∞–∫–∞–Ω—Å–∏–π:** {len(self.vacancies)}")
        
        if self.cv_data:
            experiences = [d['experience'] for d in self.cv_data.values()]
            report_lines.append(f"- **–°—Ä–µ–¥–Ω–∏–π –æ–ø—ã—Ç:** {np.mean(experiences):.1f} –ª–µ—Ç")
            report_lines.append(f"- **–ú–µ–¥–∏–∞–Ω–Ω—ã–π –æ–ø—ã—Ç:** {np.median(experiences):.1f} –ª–µ—Ç")
        
        # 2. Ground truth –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        report_lines.append("")
        report_lines.append("## üéØ Ground Truth")
        report_lines.append("")
        if GROUND_TRUTH_AVAILABLE:
            report_lines.append(f"- **–†–µ–∑—é–º–µ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π:** {len(GROUND_TRUTH_DICT)}")
            agreement = get_annotator_agreement()
            report_lines.append(f"- **–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ç–æ—Ä–æ–≤:** {agreement['mean_spearman']:.3f} (Spearman)")
        else:
            report_lines.append("- **Ground truth –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω**")
        
        # 3. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–µ—Ç–æ–¥–æ–≤
        if self.evaluation_results:
            report_lines.append("")
            report_lines.append("## üìà Methods Comparison")
            report_lines.append("")
            report_lines.append("| Method | Krippendorff's Œ± | Spearman œÅ | Acc@1 | NDCG@5 | MRR |")
            report_lines.append("|--------|-----------------|------------|-------|--------|-----|")
            
            for result in sorted(self.evaluation_results, 
                               key=lambda x: x.get('krippendorff_alpha', 0), 
                               reverse=True):
                report_lines.append(
                    f"| {result['method']} | "
                    f"{result.get('krippendorff_alpha', 0):.4f} | "
                    f"{result.get('spearman_rho', 0):.4f} | "
                    f"{result.get('accuracy_at_1', 0):.4f} | "
                    f"{result.get('ndcg@5', 0):.4f} | "
                    f"{result.get('mrr', 0):.4f} |"
                )
        
        # 4. –õ—É—á—à–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        report_lines.append("")
        report_lines.append("## üèÜ Best Configuration")
        report_lines.append("")
        report_lines.append("Based on the original paper:")
        report_lines.append("")
        report_lines.append("- **Resume:** Full text")
        report_lines.append("- **Vacancy:** BERT extractive summary (10 sentences)")
        report_lines.append("- **Text representation:** Character n-grams (1-3)")
        report_lines.append("- **Distance:** L1 (Manhattan)")
        report_lines.append("- **Krippendorff's Alpha:** 0.6287")
        
        # 5. –ù–∞—à–∏ —É–ª—É—á—à–µ–Ω–∏—è
        report_lines.append("")
        report_lines.append("## üöÄ Our Improvements")
        report_lines.append("")
        report_lines.append("- **Unified Scoring:** Keyword 80% + TF-IDF 15% + Semantic 5%")
        report_lines.append("- **Fuzzy matching:** Synonyms and partial matches")
        report_lines.append("- **Adaptive TF-IDF:** Tech boost for IT terms")
        report_lines.append("- **Chunked semantic:** Section-based similarity")
        report_lines.append("- **Ensemble:** Combined predictions from multiple methods")
        report_lines.append("- **Full pipeline:** From DOCX to evaluation report")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_file = self.output_dir / "ranking_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        print(f"\n‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
        
        return str(report_file)

    def optimize_weights_ensemble(self):
        """
        –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ 
        """
        print("\n" + "=" * 70)
        print("‚öôÔ∏è –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –í–ï–°–û–í".center(70))
        print("=" * 70)
        
        # –ü—Ä–µ–¥–æ–±—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä
        first_cv_id = list(self.cv_data.keys())[0]
        first_cv_text = self.cv_data[first_cv_id]['text']
        self.ensemble_ranker._get_vm_scores_fixed(first_cv_text, self.vacancies)
        
        best_weights = None
        best_score = -1
        
        # –¢–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã–µ –≤–µ—Å–∞, –¢–û–õ–¨–ö–û rank_ensemble 
        for unified_w in [0.4, 0.5, 0.6]:
            for vm_w in [0.2, 0.3, 0.4]:
                for bert_w in [0.1, 0.2, 0.3]:
                    weights = {
                        'unified': unified_w,
                        'vm_method': vm_w,
                        'bert_rank': bert_w
                    }
                    
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                    total = sum(weights.values())
                    weights = {k: v/total for k, v in weights.items()}
                    
                    print(f"\nüîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–µ—Å–∞: {weights}")
                    
                    # ‚úÖ –¢–û–õ–¨–ö–û rank_ensemble, –ë–ï–ó bidirectional!
                    scores = []
                    for cv_id, cv_data in self.cv_data.items():
                        if cv_id <= 30:
                            try:
                                result = self.ensemble_ranker.rank_ensemble(  # ‚Üê –ù–ï rank_bidirectional!
                                    cv_id=cv_id,
                                    cv_text=cv_data['text'],
                                    cv_skills=cv_data['skills'],
                                    vacancies=self.vacancies,
                                    cv_experience=cv_data['experience'],
                                    weights=weights
                                )
                                if cv_id in GROUND_TRUTH_DICT:
                                    gt = GROUND_TRUTH_DICT[cv_id]
                                    if result.rankings.index(1) == gt.index(1):
                                        scores.append(1)
                                    else:
                                        scores.append(0)
                            except Exception as e:
                                continue
                    
                    if scores:
                        acc1 = np.mean(scores)
                        print(f"   Accuracy@1: {acc1:.3f}")
                        if acc1 > best_score:
                            best_score = acc1
                            best_weights = weights
                            print(f"   üÜï –ù–û–í–´–ô –õ–£–ß–®–ò–ô!")
        
        print("\n" + "=" * 70)
        print(f"üèÜ –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –í–ï–°–ê: {best_weights}")
        print(f"   Accuracy@1: {best_score:.3f}")
        print("=" * 70)
        
        return best_weights

def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    parser = argparse.ArgumentParser(
        description='Job Vacancy Ranking System',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python main.py --limit 30 --method unified --evaluate
  python main.py --method all --evaluate --report
  python main.py --method vm_method --limit 10
  python main.py --method ensemble --evaluate --report
        """
    )
    
    parser.add_argument('--cv_dir', type=str, default='data/CV',
                       help='–ü–∞–ø–∫–∞ —Å —Ä–µ–∑—é–º–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DOCX')
    parser.add_argument('--vacancies', type=str, 
                       default='data/vacancies/5_vacancies.csv',
                       help='CSV —Ñ–∞–π–ª —Å 5 –≤–∞–∫–∞–Ω—Å–∏—è–º–∏')
    parser.add_argument('--output', type=str, default='results',
                       help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    parser.add_argument('--limit', type=int, default=None,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—é–º–µ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏')
    parser.add_argument('--method', type=str, default='unified',
                       choices=['unified', 'vm_method', 'okapi_bm25', 
                               'bert_rank', 'ensemble', 'all', 'bidirectional', 'competition'],
                       help='–ú–µ—Ç–æ–¥ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è')
    parser.add_argument('--no_english_only', action='store_true',
                       help='–ù–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Ä–µ–∑—é–º–µ')
    parser.add_argument('--evaluate', action='store_true',
                       help='–û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ (—Ç—Ä–µ–±—É–µ—Ç—Å—è ground truth)')
    parser.add_argument('--report', action='store_true',
                       help='–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç')
    parser.add_argument('--verbose', action='store_true', default=True,
                       help='–î–µ—Ç–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥')
    parser.add_argument('--optimize', action='store_true',
                       help='–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Å–∞ bidirectional')
    parser.add_argument('--fast', action='store_true',
                   help='–ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–µ—Å–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)')    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–∏—Å—Ç–µ–º—ã
    system = JobRankingSystem(
        cv_dir=args.cv_dir,
        vacancies_file=args.vacancies,
        output_dir=args.output
    )
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    system.load_data(
        limit_cvs=args.limit,
        english_only=not args.no_english_only,
        verbose=args.verbose
    )
    
    # –ê–Ω–∞–ª–∏–∑ –æ–ø—ã—Ç–∞
    system.analyze_experience_distribution()
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ bidirectional
    if args.optimize and not args.fast:
        print("\n" + "=" * 70)
        print("‚öôÔ∏è –ó–ê–ü–£–°–ö –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò –í–ï–°–û–í".center(70))
        print("=" * 70)
        
        optimal_weights = system.optimize_weights_ensemble()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        system.ensemble_ranker.optimal_weights = optimal_weights
    else:
        print("\n‚ö° –ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º: –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤–µ—Å–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    
        
        # –¢–∞–∫–∂–µ –æ–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞ –≤ UnifiedScorer –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if hasattr(system.unified_scorer, 'WEIGHTS'):
            print("\nüìä –¢–µ–∫—É—â–∏–µ –≤–µ—Å–∞ Unified Scorer:")
            print(f"   Keyword: {system.unified_scorer.WEIGHTS['keyword']*100}%")
            print(f"   TF-IDF: {system.unified_scorer.WEIGHTS['tfidf']*100}%")
            print(f"   Semantic: {system.unified_scorer.WEIGHTS['semantic']*100}%")    

    # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
    if args.method == 'all':
        methods = ['unified', 'vm_method', 'okapi_bm25', 'bert_rank', 'ensemble', 'bidirectional', 'competition']
        for method in methods:
            system.run_ranking(method, save_results=True, verbose=args.verbose)
    else:
        system.run_ranking(args.method, save_results=True, verbose=args.verbose)
    
    # –û—Ü–µ–Ω–∫–∞
    if args.evaluate:
        if GROUND_TRUTH_AVAILABLE:
            system.evaluate_all_methods()
        else:
            print("\n‚ùå –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ—Ü–µ–Ω–∫—É: ground truth –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
            print("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª data/annotations/ground_truth.py —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    
    # –û—Ç—á–µ—Ç
    if args.report:
        system.generate_report()
    
    print("\n" + "=" * 70)
    print("‚úÖ –ì–û–¢–û–í–û!".center(70))
    print("=" * 70)


if __name__ == "__main__":
    main()